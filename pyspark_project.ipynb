{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cdfba25-1215-4d54-a844-0d9ba3ade607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports libraries & Spark Session\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import (\n",
    "    from_json, col, split, trim, regexp_replace, when, regexp_extract, size, length, lit, current_date, from_unixtime\n",
    ")\n",
    "\n",
    "# This is required when running on my laptop with Fedora 43 and 4 CPUs, 8 GB ram\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"ETL_Flatten_Clean_Push_Postgres\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"8\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02dcf233-f732-4935-9271-1a571e2f5323",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Read downloaded JSON from kaggel & Define Schemas\n",
    "\n",
    "df = spark.read.json(\"/home/agileox/Project/payn_project/data/cc_sample_transaction.json\")\n",
    "\n",
    "address_schema = StructType([\n",
    "    StructField(\"street\", StringType(), True),\n",
    "    StructField(\"city\", StringType(), True),\n",
    "    StructField(\"state\", StringType(), True),\n",
    "    StructField(\"zip\", StringType(), True)\n",
    "])\n",
    "\n",
    "personal_schema = StructType([\n",
    "    StructField(\"person_name\", StringType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"address\", StringType(), True),\n",
    "    StructField(\"lat\", StringType(), True),\n",
    "    StructField(\"long\", StringType(), True),\n",
    "    StructField(\"city_pop\", StringType(), True),\n",
    "    StructField(\"job\", StringType(), True),\n",
    "    StructField(\"dob\", StringType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7c36876-f8e1-4979-9424-475347eee743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process to Flatten Nested JSON\n",
    "\n",
    "df_level1 = df.withColumn(\"personal_detail\", from_json(col(\"personal_detail\"), personal_schema))\n",
    "df_level2 = df_level1.withColumn(\"address\", from_json(col(\"personal_detail.address\"), address_schema))\n",
    "\n",
    "df_flat = df_level2.select(\n",
    "    col(\"Unnamed: 0\").alias(\"unnamed_id\"),   # rename here\n",
    "    \"amt\", \"category\", \"cc_bic\", \"cc_num\", \"is_fraud\",\n",
    "    \"merch_eff_time\", \"merch_last_update_time\", \"merch_lat\", \"merch_long\",\n",
    "    \"merch_zipcode\", \"merchant\", \"trans_date_trans_time\", \"trans_num\",\n",
    "    col(\"personal_detail.person_name\").alias(\"raw_person_name\"),\n",
    "    col(\"personal_detail.gender\").alias(\"gender\"),\n",
    "    col(\"personal_detail.lat\").alias(\"lat\"),\n",
    "    col(\"personal_detail.long\").alias(\"long\"),\n",
    "    col(\"personal_detail.city_pop\").alias(\"city_pop\"),\n",
    "    col(\"personal_detail.job\").alias(\"job\"),\n",
    "    col(\"personal_detail.dob\").alias(\"dob\"),\n",
    "    col(\"address.street\").alias(\"address_street\"),\n",
    "    col(\"address.city\").alias(\"address_city\"),\n",
    "    col(\"address.state\").alias(\"address_state\"),\n",
    "    col(\"address.zip\").alias(\"address_zip\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0406bd0-c08f-4281-a18d-62a0240b4bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identified not that clean data and splitting the Person Name\n",
    "\n",
    "df_names = df_flat.withColumn(\"raw_name\", regexp_replace(col(\"raw_person_name\"), \"/\", \"@\"))\n",
    "\n",
    "df_cleaned = df_names \\\n",
    "    .withColumn(\"name\", regexp_replace(col(\"raw_name\"), r\"[@|!]+\", \",\")) \\\n",
    "    .withColumn(\"name\", regexp_replace(col(\"name\"), r\"\\bNOOOO\\b\", \"\")) \\\n",
    "    .withColumn(\"name\", regexp_replace(col(\"name\"), r\"\\beeeee\\b\", \"\")) \\\n",
    "    .withColumn(\"name\", regexp_replace(col(\"name\"), r\",\\s*,\", \",\")) \\\n",
    "    .withColumn(\"name\", regexp_replace(col(\"name\"), r\"\\s+\", \" \")) \\\n",
    "    .withColumn(\"name\", trim(col(\"name\"))) \\\n",
    "    .withColumn(\"name\", regexp_replace(col(\"name\"), r\"^,+|,+$\", \"\"))\n",
    "\n",
    "tokens = split(col(\"name\"), r\"[ ,]+\")\n",
    "first_tok = tokens.getItem(0)\n",
    "second_tok = tokens.getItem(1)\n",
    "\n",
    "df_split = df_cleaned \\\n",
    "    .withColumn(\"first_tok\", first_tok) \\\n",
    "    .withColumn(\"second_tok\", when((size(tokens) >= 2) & (length(second_tok) > 0), second_tok))\n",
    "\n",
    "df_final = df_split \\\n",
    "    .withColumn(\n",
    "        \"first_name\",\n",
    "        when(col(\"second_tok\").isNull(),\n",
    "             regexp_extract(col(\"name\"), r\"^([A-Z][a-z]+)\", 1)\n",
    "        ).otherwise(col(\"first_tok\"))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"last_name\",\n",
    "        when(col(\"second_tok\").isNull(),\n",
    "             regexp_extract(col(\"name\"), r\"^[A-Z][a-z]+([A-Z][a-z]+)\", 1)\n",
    "        ).otherwise(col(\"second_tok\"))\n",
    "    ) \\\n",
    "    .drop(\"first_tok\", \"second_tok\", \"raw_person_name\", \"raw_name\", \"name\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6fc7efb-1ec3-4c56-8108-780d0c0acf75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Gender to Female and Male\n",
    "\n",
    "df_final = df_final.withColumn(\n",
    "    \"gender\",\n",
    "    when(col(\"gender\") == \"F\", \"Female\")\n",
    "    .when(col(\"gender\") == \"M\", \"Male\")\n",
    "    .otherwise(col(\"gender\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "285b7efb-7e71-493a-8bcb-c5718bf65424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask Credit Card Number (keep last 4 digits) & Postcode (keep 2 digits)\n",
    "\n",
    "cc_digits = regexp_replace(col(\"cc_num\").cast(\"string\"), r\"\\D\", \"\")\n",
    "df_final = df_final.withColumn(\n",
    "    \"cc_num_masked\",\n",
    "    when(length(cc_digits) >= 4,\n",
    "         regexp_replace(cc_digits, r\"\\d(?=\\d{4})\", \"*\")\n",
    "    ).otherwise(lit(None))\n",
    ").drop(\"cc_num\")\n",
    "\n",
    "addr_zip = regexp_replace(col(\"address_zip\").cast(\"string\"), r\"\\D\", \"\")\n",
    "df_final = df_final.withColumn(\n",
    "    \"address_zip_masked\",\n",
    "    when(length(addr_zip) >= 2,\n",
    "         regexp_replace(addr_zip, r\"\\d(?=\\d{2})\", \"*\")\n",
    "    ).otherwise(lit(None))\n",
    ").drop(\"address_zip\")\n",
    "\n",
    "addr_street = col(\"address_street\").cast(\"string\")\n",
    "df_final = df_final.withColumn(\n",
    "    \"address_street_masked\",\n",
    "    when(length(addr_street) >= 3,\n",
    "         # replace first 3 digits with '*'\n",
    "         regexp_replace(addr_street, r\"^\\d{3}\", \"***\")\n",
    "    ).otherwise(lit(None))\n",
    ").drop(\"address_street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c430d398-ea0b-4693-8bda-daac881ad738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Casting the proper data type for the used of inserting into Postgresql DB\n",
    "\n",
    "df_final = df_final \\\n",
    "    .withColumn(\"amt\", col(\"amt\").cast(\"double\")) \\\n",
    "    .withColumn(\"city_pop\", col(\"city_pop\").cast(\"int\")) \\\n",
    "    .withColumn(\"dob\", col(\"dob\").cast(\"date\")) \\\n",
    "    .withColumn(\"is_fraud\", col(\"is_fraud\").cast(\"boolean\")) \\\n",
    "    .withColumn(\"trans_date_trans_time\", col(\"trans_date_trans_time\").cast(\"timestamp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab444427-f2c5-4fae-914f-308081dfadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# handling the timestamp matters\n",
    "\n",
    "df_final = df_final.withColumn(\n",
    "    \"merch_eff_time\",\n",
    "    when(length(col(\"merch_eff_time\").cast(\"string\")) == 16,  # microseconds\n",
    "         from_unixtime((col(\"merch_eff_time\").cast(\"bigint\")/1000000).cast(\"bigint\")))\n",
    "    .when(length(col(\"merch_eff_time\").cast(\"string\")) == 13,  # milliseconds\n",
    "         from_unixtime((col(\"merch_eff_time\").cast(\"bigint\")/1000).cast(\"bigint\")))\n",
    "    .when(length(col(\"merch_eff_time\").cast(\"string\")) == 10,  # seconds\n",
    "         from_unixtime(col(\"merch_eff_time\").cast(\"bigint\")))\n",
    "    .otherwise(None)\n",
    "    .cast(\"timestamp\")\n",
    ")\n",
    "\n",
    "df_final = df_final.withColumn(\n",
    "    \"merch_last_update_time\",\n",
    "    when(length(col(\"merch_last_update_time\").cast(\"string\")) == 16,  # microseconds\n",
    "         from_unixtime((col(\"merch_last_update_time\").cast(\"bigint\")/1000000).cast(\"bigint\")))\n",
    "    .when(length(col(\"merch_last_update_time\").cast(\"string\")) == 13,  # milliseconds\n",
    "         from_unixtime((col(\"merch_last_update_time\").cast(\"bigint\")/1000).cast(\"bigint\")))\n",
    "    .when(length(col(\"merch_last_update_time\").cast(\"string\")) == 10,  # seconds\n",
    "         from_unixtime(col(\"merch_last_update_time\").cast(\"bigint\")))\n",
    "    .otherwise(None)\n",
    "    .cast(\"timestamp\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "19e62338-da7c-4b4b-b417-e75ce23fc67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the ingestion date before pushing to PG DB\n",
    "\n",
    "df_final = df_final.withColumn(\"ingestion_date\", current_date())\n",
    "#df_final = df_final.withColumn(\"ingestion_date\", lit(\"2025-11-23\").cast(\"date\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "078653f6-13e1-45f8-8563-c9d780589caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify\n",
    "\n",
    "#print(\"Row count:\", df_final.count())\n",
    "#df_final.show(100, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9bbbeb20-c57c-45c0-8aaa-786dbf5497e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Push to PostgreSQL DB\n",
    "\n",
    "jdbc_url = \"jdbc:postgresql://localhost:5432/postgres\"\n",
    "connection_properties = {\n",
    "    \"user\": \"payn_user\",\n",
    "    \"password\": \"welcome1\",\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "\n",
    "df_final.write \\\n",
    "    .jdbc(\n",
    "        url=jdbc_url,\n",
    "        table=\"payn_etl.cleaned_transactions_partition\",   # schema-qualified\n",
    "        mode=\"append\",\n",
    "        properties=connection_properties\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed0a9ee-84e5-4d14-b246-75c47d1d8bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (Spark)",
   "language": "python",
   "name": "python311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
